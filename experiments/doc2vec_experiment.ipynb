{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-fzpce3SBuk",
    "outputId": "cfd6b2c0-77de-4bd7-bba7-93b31bfcee5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==4.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gensim==4.3.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gensim==4.3.2) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gensim==4.3.2) (7.0.4)\n",
      "Requirement already satisfied: wrapt in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim==4.3.2) (1.16.0)\n",
      "Requirement already satisfied: mlflow==2.12.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.12.1)\n",
      "Requirement already satisfied: Flask<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (3.0.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (1.13.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (2.2.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (6.1.3)\n",
      "Requirement already satisfied: entrypoints<1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (3.1.43)\n",
      "Requirement already satisfied: graphene<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (3.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (6.11.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (3.6)\n",
      "Requirement already satisfied: matplotlib<4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (3.8.3)\n",
      "Requirement already satisfied: numpy<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (1.26.4)\n",
      "Requirement already satisfied: packaging<25 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (21.3)\n",
      "Requirement already satisfied: pandas<3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (1.5.3)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (4.25.3)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (15.0.2)\n",
      "Requirement already satisfied: pytz<2025 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (2024.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (6.0.1)\n",
      "Requirement already satisfied: querystring-parser<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (1.2.4)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (1.4.1.post1)\n",
      "Requirement already satisfied: scipy<2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (1.12.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (2.0.29)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (0.5.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (3.1.3)\n",
      "Requirement already satisfied: gunicorn<22 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from mlflow==2.12.1) (21.2.0)\n",
      "Requirement already satisfied: Mako in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.12.1) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.12.1) (4.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow==2.12.1) (2.2.1)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow==2.12.1) (1.7.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow==2.12.1) (3.0.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow==2.12.1) (2.1.2)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Flask<4->mlflow==2.12.1) (1.7.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow==2.12.1) (4.0.11)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4->mlflow==2.12.1) (3.2.3)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4->mlflow==2.12.1) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from graphene<4->mlflow==2.12.1) (9.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.12.1) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow==2.12.1) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1) (2.9.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from querystring-parser<2->mlflow==2.12.1) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.12.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.12.1) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.12.1) (2024.2.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2->mlflow==2.12.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn<2->mlflow==2.12.1) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.12.1) (3.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.12.1) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==4.3.2\n",
    "!pip install mlflow==2.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "EtTEWm9hZ5og"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch as torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-08 16:36:55 aws-glue-assets-499751399505-ca-central-1\r\n",
      "2023-07-16 19:22:33 madhav-krishna-demo\r\n",
      "2024-01-31 04:07:29 mini-pipeline-project\r\n",
      "2024-04-11 00:49:21 sagemaker-ca-central-1-499751399505\r\n",
      "2024-04-11 00:49:18 sagemaker-studio-499751399505-l6sukv6beie\r\n",
      "2024-03-04 03:48:55 wcd-project-twitter-datasets\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DPHUPdGhT8QN",
    "outputId": "9cbcb2a3-8154-43cd-ed8c-7509fb567577"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2401</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id     label                                               text\n",
       "0  2401  Positive  im getting on borderlands and i will murder yo...\n",
       "1  2401  Positive  I am coming to the borders and I will kill you...\n",
       "2  2401  Positive  im getting on borderlands and i will kill you ...\n",
       "3  2401  Positive  im coming on borderlands and i will murder you...\n",
       "4  2401  Positive  im getting on borderlands 2 and i will murder ..."
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "S3_BUCKET = os.environ.get(\"S3_BUCKET\")\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(S3_BUCKET, 'data/training/twitter_training.csv', 'twitter_training.csv')\n",
    "s3.download_file(S3_BUCKET, 'data/test/test-training.csv', 'twitter_validation.csv')\n",
    "\n",
    "\n",
    "training_df = pd.read_csv('twitter_training.csv', names = [\"id\", \"account\", \"label\", \"text\"])\n",
    "test_df = pd.read_csv('twitter_validation.csv', names = [\"id\", \"account\", \"label\", \"text\"])\n",
    "\n",
    "training_df.pop('account')\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8OYSb3iYg6I",
    "outputId": "f07c068f-f64b-4cea-a36e-814dc901ac88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686\n",
      "0\n",
      "0\n",
      "0\n",
      "3472 3757 3053\n"
     ]
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "print(len(training_df[training_df[\"text\"].isnull()]))\n",
    "print(len(training_df[training_df[\"label\"].isnull()]))\n",
    "print(len(test_df[test_df[\"text\"].isnull()]))\n",
    "print(len(test_df[test_df[\"label\"].isnull()]))\n",
    "\n",
    "training_df['text'].fillna('', inplace=True)\n",
    "training_df['label'].fillna('Neutral', inplace=True)\n",
    "test_df['text'].fillna('', inplace=True)\n",
    "test_df['label'].fillna('Neutral', inplace=True)\n",
    "\n",
    "training_df = training_df.groupby(['id', 'label']).agg({'text': ' '.join}).reset_index()\n",
    "test_df = test_df.groupby(['id', 'label']).agg({'text': ' '.join}).reset_index()\n",
    "\n",
    "print(len(training_df[training_df[\"label\"] == \"Positive\"]), \\\n",
    "      len(training_df[training_df[\"label\"] == \"Negative\"]), \\\n",
    "      len(training_df[training_df[\"label\"] == \"Neutral\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nU77hahYl_Ot",
    "outputId": "1cac9319-83a6-4d87-b812-d07ffde7775c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12447\n",
      "9957\n",
      "2778 3005 2442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "Positive = [training_df[\"label\"] == \"Positive\", test_df[\"label\"] == \"Positive\"]\n",
    "Negative = [training_df[\"label\"] == \"Negative\", test_df[\"label\"] == \"Negative\"]\n",
    "Neutral = [training_df[\"label\"] == \"Neutral\", test_df[\"label\"] == \"Neutral\"]\n",
    "\n",
    "training_df[\"Positive\"], training_df[\"Negative\"], training_df[\"Neutral\"] = \\\n",
    "Positive[0], Negative[0], Neutral[0]\n",
    "\n",
    "test_df[\"Positive\"], test_df[\"Negative\"], test_df[\"Neutral\"] = \\\n",
    "Positive[1], Negative[1], Neutral[1]\n",
    "\n",
    "training_train_df, training_val_df = train_test_split(training_df, train_size \\\n",
    "                                                      = 0.8, stratify=training_df[\"label\"])\n",
    "print(len(training_df))\n",
    "print(len(training_train_df))\n",
    "print(len(training_train_df[training_train_df['label'] == 'Positive']), \\\n",
    "      len(training_train_df[training_train_df['label'] == 'Negative']), \\\n",
    "      len(training_train_df[training_train_df['label'] == 'Neutral']))\n",
    "\n",
    "class Texts(Dataset):\n",
    "  def __init__(self, df):\n",
    "    self.df = df\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "  def __getitem__(self, index):\n",
    "    text = self.df.iloc[index].at['text']\n",
    "    positive = self.df.iloc[index].at['Positive']\n",
    "    negative = self.df.iloc[index].at['Negative']\n",
    "    neutral = self.df.iloc[index].at['Neutral']\n",
    "    label = torch.tensor([int(positive),\\\n",
    "                          int(negative),\\\n",
    "                          int(neutral)])\n",
    "    return (text, label)\n",
    "\n",
    "training_dataset = Texts(training_train_df)\n",
    "validation_dataset = Texts(training_val_df)\n",
    "test_dataset = Texts(test_df)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "train_dataloaders = {'train': DataLoader(training_dataset, batch_size = BATCH_SIZE),\n",
    "                     'val': DataLoader(validation_dataset, batch_size=BATCH_SIZE)}\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ghzHPqC_5sgy"
   },
   "outputs": [],
   "source": [
    "\n",
    "from numpy import mean\n",
    "import numpy as np\n",
    "from gensim.utils import simple_preprocess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def training_loop(dataloader, model1, model2, epochs, loss_function, optimizer, scheduler = None):\n",
    "  #model1 is the doc2vec and model2 is the softmax layer, its assumed that\n",
    "  #model1 is trained\n",
    "  epoch_c_matrices = []\n",
    "  epoch_losses = []\n",
    "  for epoch in range(epochs):\n",
    "    print(\"Epoch: \" + str(epoch))\n",
    "    epoch_c_matrix = np.zeros((3,3))\n",
    "    batch_losses = []\n",
    "    for x in ['train', 'val']:\n",
    "      model2.to(device)\n",
    "      if x == 'train':\n",
    "        model2.train()\n",
    "      else:\n",
    "        model2.eval()\n",
    "      for (data, label) in dataloader[x]:\n",
    "        data = list(data)\n",
    "        label = label.to(torch.float32).to(device)\n",
    "        data = Tensor(np.asarray([model1.infer_vector(simple_preprocess(text)) for text in data]))\n",
    "        data.to(device)\n",
    "        output = model2(data)\n",
    "        ###\n",
    "        output.to(device)\n",
    "        loss = loss_function(output, label)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "          predictions = torch.argmax(output.to('cpu'), 1)\n",
    "          label = torch.argmax(label.to('cpu'), 1)\n",
    "\n",
    "        if x == 'train':\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "        else:\n",
    "          c_matrix = confusion_matrix(label, predictions, labels=[0,1,2])\n",
    "          epoch_c_matrix += c_matrix\n",
    "          batch_losses.append(loss.item())\n",
    "\n",
    "\n",
    "    epoch_loss = mean(batch_losses)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "\n",
    "    epoch_c_matrices.append(epoch_c_matrix)\n",
    "    print(\"The accuracy is: \")\n",
    "    print((epoch_c_matrix[0][0] + epoch_c_matrix[1][1] + epoch_c_matrix[2][2])/np.sum(epoch_c_matrix))\n",
    "#     print(\"current epoch c matrix:\")\n",
    "#     print(epoch_c_matrices[-1])\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(epoch_loss)\n",
    "\n",
    "  return epoch_c_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TaggedDocument<['the', 'most', 'boring', 'game', 've', 'ever', 'played', 'the', 'most', 'boring', 'game', 've', 'ever', 'played', 'the', 'most', 'boring', 'game', 've', 'ever', 'played', 'the', 'most', 'violent', 'game', 've', 'ever', 'played', 'the', 'most', 'boring', 'single', 'game', 've', 'ever', 'played', 'the', 'most', 'boring', 'game', 've', 'yet', 'played'], [0]>\n",
      "['gamespot', 'borderlands', 'dlc', 'dismisses', 'major', 'problems', 'with', 'lovecraft', 'work', 'ift', 'tt', 'qpeis', 'gamespot', 'borderlands', 'dlc', 'rejects', 'major', 'issues', 'with', 'lovecraft', 'work', 'ift', 'tt', 'qpeis', 'gamespot', 'dlc', 'borderlands', 'fires', 'protagonists', 'over', 'lovecraft', 'tt', 'qs', 'gamespot', 'borderlands', 'dlc', 'dismisses', 'major', 'problems', 'lovecraft', 'dream', 'ift', 'tt', 'qpeis', 'official', 'gamespot', 'lost', 'borderlands', 'dlc', 'dismisses', 'major', 'problems', 'running', 'with', 'lovecraft', 'underground', 'work', 'as', 'ift', 'tt', 'qpeis', 'gamespot', 'fantasy', 'iii', 'music', 'has', 'major', 'problems', 'with', 'lovecraft', 'work', 'ift', 'tt', 'qpeis']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "def create_documents(corpus, tokens_only= False):\n",
    "  new_corpus = []\n",
    "  for i, text in enumerate(corpus):\n",
    "    tokens = simple_preprocess(text)\n",
    "    if not tokens_only:\n",
    "      new_corpus.append(TaggedDocument(tokens, [i]))\n",
    "    else:\n",
    "      new_corpus.append(tokens)\n",
    "  return new_corpus\n",
    "\n",
    "train_corpus = create_documents(training_train_df['text'])\n",
    "test_corpus = create_documents(test_df['text'], tokens_only = True)\n",
    "print(train_corpus[0])\n",
    "print(test_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validate(test_dataloader, model1, model2):\n",
    "    batch_c_matrix = np.zeros((3,3))\n",
    "    for (data, label) in test_dataloader:\n",
    "        data = list(data)\n",
    "        label = label.to(torch.float32).to(device)\n",
    "        data = Tensor(np.asarray([model1.infer_vector(simple_preprocess(text)) for text in data]))\n",
    "        data.to(device)\n",
    "        output = model2(data)\n",
    "        ###\n",
    "        output.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "          predictions = torch.argmax(output.to('cpu'), 1)\n",
    "          label = torch.argmax(label.to('cpu'), 1)\n",
    "          c_matrix = confusion_matrix(label, predictions, labels=[0,1,2])\n",
    "          batch_c_matrix += c_matrix\n",
    "    return batch_c_matrix\n",
    "\n",
    "def accuracy(batch_matrix):\n",
    "    a = (batch_matrix[0][0] + batch_matrix[1][1] + batch_matrix[2][2])/np.sum(batch_matrix)\n",
    "    return a\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "class Doc2VecWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        from gensim.models.doc2vec import Doc2Vec\n",
    "        doc2vec_file_path = context.artifacts['doc2vec_file_path']\n",
    "        self.model = Doc2Vec.load(doc2vec_file_path)\n",
    "        \n",
    "    def __init__(self):\n",
    "        super(Doc2VecWrapper, self).__init__()\n",
    "        self.model = None\n",
    "        \n",
    "    def predict(self, context, model_input):\n",
    "        return self.model.infer_vector(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://ec2-99-79-55-202.ca-central-1.compute.amazonaws.com:5000'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='s3://wcd-project-twitter-datasets/artifacts/2', creation_time=1714524225208, experiment_id='2', last_update_time=1714524225208, lifecycle_stage='active', name='doc2vec experiment 2', tags={}>,\n",
       " <Experiment: artifact_location='s3://wcd-project-twitter-datasets/artifacts/1', creation_time=1713313446007, experiment_id='1', last_update_time=1713313446007, lifecycle_stage='active', name='doc2vec experiment', tags={}>,\n",
       " <Experiment: artifact_location='s3://wcd-project-twitter-datasets/artifacts/0', creation_time=1712889391161, experiment_id='0', last_update_time=1712889391161, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Below is subject to change\n",
    "TRACKING_SERVER_HOST = os.environ.get(\"TRACKING_SERVER_HOST\")\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")\n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "The accuracy is: \n",
      "0.5413654618473895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a50bd5c1414f54bf12f7e12cf845e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/01 00:48:46 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.12.1, required: mlflow==2.11.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2024/05/01 00:48:59 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpijsl2jsa/model/data, flavor: pytorch). Fall back to return ['torch==2.1.0', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback. \n",
      "2024/05/01 00:48:59 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.12.1, required: mlflow==2.11.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch.optim as optim\n",
    "\n",
    "VECTOR_SIZE = 10\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "lr = 5e-4\n",
    "dropout = 0.3\n",
    "epochs = 1\n",
    "\n",
    "mlflow.set_experiment(\"doc2vec experiment 2\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    \n",
    "    run_id = run.info.run_id\n",
    "    params = {'VECTOR_SIZE':VECTOR_SIZE, 'NUM_CLASSES':NUM_CLASSES, 'lr':lr, 'dropout':dropout,\\\n",
    "          'BATCH_SIZE':BATCH_SIZE, 'epochs':epochs}\n",
    "\n",
    "    model1 = gensim.models.doc2vec.Doc2Vec(vector_size=VECTOR_SIZE, min_count=2, epochs=40)\n",
    "    model1.build_vocab(train_corpus)\n",
    "\n",
    "    model1.train(train_corpus, total_examples=model1.corpus_count, epochs=model1.epochs)\n",
    "    model2 = nn.Sequential(nn.Linear(VECTOR_SIZE, NUM_CLASSES), nn.Softmax(dim = 1))\n",
    "\n",
    "    loss_function = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model2.parameters(), lr = lr, weight_decay=5e-4, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.6)\n",
    "    args = training_loop(train_dataloaders, model1, model2, epochs, loss_function, optimizer, scheduler)\n",
    "    \n",
    "    model1.save('doc2vec.pkl')\n",
    "    mlflow.pyfunc.log_model(artifact_path = \"doc2vec_doc_embedding\",python_model= Doc2VecWrapper(), \\\n",
    "                            artifacts = {'doc2vec_file_path': 'doc2vec.pkl'}, pip_requirements=[\"gensim==4.3.2\"])\n",
    "    mlflow.pytorch.log_model(model2, artifact_path=\"doc2vec_classification\")\n",
    "    #logging the model accuracy\n",
    "    validation = validate(train_dataloaders['val'], model1, model2)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy(validation))\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'doc2vec_doc_embedding' already exists. Creating a new version of this model...\n",
      "2024/05/01 01:08:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: doc2vec_doc_embedding, version 3\n",
      "Created version '3' of model 'doc2vec_doc_embedding'.\n",
      "Registered model 'doc2vec_classification' already exists. Creating a new version of this model...\n",
      "2024/05/01 01:08:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: doc2vec_classification, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b9036f41898546d5830181307ad80978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'doc2vec_classification'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Register the best model\n",
    "highest_accuracy_run_id = mlflow.search_runs(\n",
    "    experiment_names=[\"doc2vec experiment 2\"],\n",
    "    max_results=1,\n",
    "    order_by=[\"metrics.accuracy DESC\"],\n",
    ")['run_id'][0]\n",
    "\n",
    "print(highest_accuracy_run_id)\n",
    "\n",
    "embedding = mlflow.register_model(f\"runs:/{highest_accuracy_run_id}/doc2vec_doc_embedding\", \"doc2vec_doc_embedding\")\n",
    "\n",
    "classification = mlflow.register_model(f\"runs:/{highest_accuracy_run_id}/doc2vec_classification\", \"doc2vec_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e76299bddf04858b08936f9b0a82c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/05 23:41:42 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n",
      "2024/05/05 23:41:43 WARNING mlflow.utils.requirements_utils: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.12.1, required: mlflow==2.11.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496913a8b0614e89ae7535b25b8e97d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/05 23:41:44 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (1): Softmax(dim=1)\n",
      ")\n",
      "tensor([[-0.2221, -0.5706,  0.2081, -0.1777,  0.1867, -0.0440,  0.2745, -0.0332,\n",
      "         -0.5207,  0.1626]])\n",
      "tensor([[0.3635, 0.3695, 0.2670]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Simple test of model regitering\n",
    "model_version = 3\n",
    "embedding_model = mlflow.pyfunc.load_model(model_uri=f\"models:/doc2vec_doc_embedding/{model_version}\")\n",
    "classification_model = mlflow.pytorch.load_model(model_uri=f\"models:/doc2vec_classification/{model_version}\")\n",
    "print(classification_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1331, -0.4910,  0.2949, -0.1147,  0.1475, -0.0035,  0.2693, -0.0062,\n",
      "         -0.3912,  0.1886]])\n",
      "tensor([[0.3652, 0.3627, 0.2721]])\n"
     ]
    }
   ],
   "source": [
    "tweet = \"this is a random tweet\"\n",
    "data = Tensor(embedding_model.predict(data=simple_preprocess(tweet)))\n",
    "data = data.unsqueeze(0)\n",
    "print(data)\n",
    "classification_model.eval()\n",
    "with torch.no_grad():\n",
    "    output = classification_model(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
